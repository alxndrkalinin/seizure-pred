{
 "metadata": {
  "name": "",
  "signature": "sha256:235e5824b9c303d622c98f0cb3c34f89c81f382a68b2b7b1fb2ef5a0c2b1d1f7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from __future__ import division\n",
      "import os, sys, glob, itertools\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats, fft\n",
      "from scipy.signal import butter, lfilter\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.feature_selection import RFECV\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RandomForestClassifierWithCoef(RandomForestClassifier):\n",
      "    def fit(self, *args, **kwargs):\n",
      "        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)\n",
      "        self.coef_ = self.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyDir = 'healthy'\n",
      "epilepticDir = 'epileptic'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 377
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readData(dirName):\n",
      "    pwd = os.path.dirname(os.path.realpath(dirName))\n",
      "\n",
      "    allFiles = glob.glob(pwd + '/' + dirName + '/*.txt')\n",
      "    frames = []\n",
      "\n",
      "    for fileName in allFiles:\n",
      "        series = pd.read_csv(fileName, header=None, sep='\\n', index_col=False)\n",
      "        series = series.transpose()\n",
      "        frames.append(series)\n",
      "    \n",
      "    df = pd.concat(frames)\n",
      "    df = df.reset_index(drop = 1)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 378
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyDf = readData(healthyDir)\n",
      "epilepticDf = readData(epilepticDir)\n",
      "print(healthyDf.shape)\n",
      "print(epilepticDf.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 4097)\n",
        "(100, 4097)\n"
       ]
      }
     ],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
      "    nyq = 0.5 * fs\n",
      "    low = lowcut / nyq\n",
      "    high = highcut / nyq\n",
      "    b, a = butter(order, [low, high], btype = 'band')\n",
      "    return b, a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 380
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare 8 overlapping log-spaced bandpass filters between 0.53 and 40Hz\n",
      "filters = []\n",
      "fs = 173.61\n",
      "for i in range(8):\n",
      "    x = np.logspace(np.log10(0.53), np.log10(40), 10)\n",
      "    filters.append(butter_bandpass(x[i], np.floor(x[i + 2]), fs, 3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 381
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create combinatorial filter sets up to size 4. Output is global idexing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List of all possible combinations of 4 or fewer filters\n",
      "wis = list(itertools.chain(itertools.combinations(range(8), 1),\n",
      "                           itertools.combinations(range(8), 2),\n",
      "                           itertools.combinations(range(8), 3),\n",
      "                           itertools.combinations(range(8), 4)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 382
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_features(signal):\n",
      "    feat = []\n",
      "    for b, a in filters:\n",
      "        f = lfilter(b, a, signal)\n",
      "        covar = np.cov(f)\n",
      "        ampl = np.sum(np.absolute(f)) / np.sum(np.absolute(signal).sum())\n",
      "        power = np.sum(np.power(f, 2)) / np.sum(np.power(signal, 2).sum())\n",
      "        feat = np.append(feat, [covar, ampl, power])\n",
      "    return pd.Series(feat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 383
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyLabels = np.zeros(healthyDf.shape[0], dtype=np.int)\n",
      "epilepticLables = np.ones(epilepticDf.shape[0], dtype=np.int)\n",
      "\n",
      "labels = np.append(healthyLabels, epilepticLables)\n",
      "\n",
      "healthyFeat = healthyDf.apply(extract_features, axis=1)\n",
      "epilepticFeat = epilepticDf.apply(extract_features, axis=1)\n",
      "\n",
      "features = healthyFeat.append(epilepticFeat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 384
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFeaturesForFilterSet (features, filterSet):\n",
      "    return pd.concat([features.iloc[:, 3 * filter : 3 * (filter + 1)] for filter in filterSet], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 385
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auc_scores = []\n",
      "ig_scores = []\n",
      "rfs_scores = []\n",
      "\n",
      "def binFreq(arr):\n",
      "    nonZeroFreq = np.count_nonzero(arr) / len(arr)\n",
      "    return [nonZeroFreq, 1 - nonZeroFreq]\n",
      "\n",
      "for w in wis:\n",
      "    \n",
      "    # get features for current set of filters using global indices\n",
      "    featureSet = getFeaturesForFilterSet(features, w)\n",
      "    \n",
      "    y = labels\n",
      "    X = featureSet.values\n",
      "\n",
      "    ps = []\n",
      "    fs = []\n",
      "    rfs = []\n",
      "    for train, test in cv.ShuffleSplit(X.shape[0], random_state=42):\n",
      "        X_train = X[train]\n",
      "        X_test = X[test]\n",
      "        y_train = y[train]\n",
      "        y_test = y[test]\n",
      "\n",
      "        clf = SGDClassifier(loss='log', penalty='l1', alpha=0.0001)    \n",
      "        clf.fit(X_train, y_train)     \n",
      "        y_pred = clf.predict(X_test)\n",
      "\n",
      "        ras = roc_auc_score(y_test, y_pred)\n",
      "        igs = stats.entropy(binFreq(y_pred), binFreq(y_test))\n",
      "        ps.append(ras)\n",
      "        fs.append(igs)\n",
      "\n",
      "        \n",
      "    ps = np.array(ps)\n",
      "    fs = np.array(fs)\n",
      "    rfs = np.array(rfs)\n",
      "    auc_scores.append(ps.mean())\n",
      "    ig_scores.append(fs.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 386
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select 5 best filter sets from each selection scheme\n",
      "best_auc = sorted(zip(auc_scores, wis))[-5:]\n",
      "best_ig = sorted(zip(ig_scores, wis))[:5]\n",
      "\n",
      "print(best_auc)\n",
      "print(best_ig)\n",
      "\n",
      "best_auc_ind = list(x[1] for x in best_auc)\n",
      "best_ig_ind = list(x[1] for x in best_ig)\n",
      "\n",
      "# choose filter sets that include filters from best AUC list\n",
      "elems = set(itertools.chain.from_iterable(best_auc_ind))\n",
      "best_filters = [tup for tup in best_ig_ind if elems.issuperset(tup)]\n",
      "print(best_filters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0.58969336219336221, (0, 1, 2, 3)), (0.59023809523809523, (0, 1, 6)), (0.610669191919192, (0, 3)), (0.61897907647907657, (0, 2, 3)), (0.62044372294372307, (0, 1, 3))]\n",
        "[(0.33872509586235128, (0, 2, 3, 5)), (0.352665514604522, (0, 3)), (0.35804412756429993, (0, 1, 3)), (0.37052472784659302, (0, 2, 3)), (0.39300911656660331, (0, 2, 3, 4))]\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'tuple' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-390-d15be8c6c096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# choose filter sets that include filters from best AUC list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auc_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbest_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_ig_ind\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
       ]
      }
     ],
     "prompt_number": 390
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifiers = [\n",
      "    LinearSVC(dual=False),\n",
      "    SVC(),\n",
      "    Lasso(),\n",
      "    KNeighborsClassifier(),\n",
      "    AdaBoostClassifier(),\n",
      "    RandomForestClassifier(n_estimators=200, n_jobs=-1),\n",
      "    GradientBoostingClassifier(n_estimators=200, warm_start=False)\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 388
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter_best_auc = []\n",
      "\n",
      "for feat_set in best_filters:\n",
      "    print('\\nFILTERS:' + str(feat_set))\n",
      "    \n",
      "    featureSet = getFeaturesForFilterSet(features, feat_set)\n",
      "    \n",
      "    y = labels\n",
      "    X = featureSet.values\n",
      "    \n",
      "    clfs_auc = []\n",
      "\n",
      "    for clf in classifiers:\n",
      "\n",
      "        aucs = []\n",
      "    \n",
      "        for train, test in cv.KFold(X.shape[0], n_folds=5, shuffle=True, random_state=24):\n",
      "            X_train = X[train]\n",
      "            X_test = X[test]\n",
      "            y_train = y[train]\n",
      "            y_test = y[test]\n",
      "            \n",
      "            clf.fit(X_train, y_train)\n",
      "            y_pred = clf.predict(X_test)\n",
      "\n",
      "            auc = roc_auc_score(y_test, y_pred)\n",
      "            aucs.append(auc)\n",
      "\n",
      "        avg_auc = np.mean(aucs)\n",
      "        print(avg_auc)\n",
      "        clfs_auc.append(avg_auc)\n",
      "\n",
      "    best_auc_clf = sorted(zip(clfs_auc, classifiers))[-1:]\n",
      "    print(best_auc_clf)\n",
      "    filter_best_auc.append(best_auc_clf[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "FILTERS:((0.99444444444444446, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')), (0, 1, 3))\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "can only concatenate tuple (not \"int\") to tuple",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-389-0a1c69b2ee36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFILTERS:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfeatureSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFeaturesForFilterSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-385-618eb1e98a13>\u001b[0m in \u001b[0;36mgetFeaturesForFilterSet\u001b[0;34m(features, filterSet)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetFeaturesForFilterSet\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilterSet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"int\") to tuple"
       ]
      }
     ],
     "prompt_number": 389
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FilterSets = sorted(zip(filter_best_auc, best_filters))\n",
      "scores = [set[0][0] for set in FilterSets]\n",
      "numMaxScores = len([i for i, s in enumerate(scores) if s == scores[-1:]])\n",
      "bestFilterSets = FilterSets[-1 * numMaxScores:]\n",
      "print(bestFilterSets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[((0.99444444444444446, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')), ((0.99444444444444446, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')), (0, 1, 3))), ((0.99444444444444446, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')), ((0.99444444444444446, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')), (0, 3)))]\n"
       ]
      }
     ],
     "prompt_number": 368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, fs in enumerate(bestFilterSets):\n",
      "\n",
      "    clf = best_filter[i][0][1]\n",
      "    \n",
      "    if not hasattr(clf, 'coef_'):\n",
      "        if ((clf.__class__.__name__ == 'RandomForestClassifier')):\n",
      "            clf = RandomForestClassifierWithCoef(n_estimators=200, n_jobs=-1)\n",
      "        else:\n",
      "            print('Cannot do further feature reduction for ' + str(clf))\n",
      "            print('Used filters: ' + str(best_filter[i][1]))\n",
      "            print('Achieved accuracy: ' + str(best_filter[i][0][0]))\n",
      "    else:\n",
      "        featureSet = getFeaturesForFilterSet(features, best_filter[0][1])\n",
      "        X = featureSet.values\n",
      "\n",
      "        rfecv = RFECV(estimator=clf, step=1, cv=cv.KFold(X.shape[0], n_folds=5, shuffle=True), scoring='roc_auc')\n",
      "        rfecv.fit(X, y)\n",
      "\n",
      "        print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
      "\n",
      "        # Plot number of features VS. cross-validation scores\n",
      "        plt.figure()\n",
      "        plt.xlabel(\"Number of features selected\")\n",
      "        plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
      "        plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
      "        plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cannot do further feature reduction for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
        "Used filters: (0, 1, 3)\n",
        "Achieved accuracy: 0.994444444444\n",
        "Cannot do further feature reduction for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
        "Used filters: (0, 3)\n",
        "Achieved accuracy: 0.994444444444\n"
       ]
      }
     ],
     "prompt_number": 371
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accs = []\n",
      "aucs = []\n",
      "cm = np.zeros((2,2))\n",
      "\n",
      "selectedFeatInd = rfecv.get_support(indices=True)\n",
      "featureSet = getFeaturesForFilterSet(features, best_filter[0][1])\n",
      "X = featureSet.iloc[:, selectedFeatInd].values\n",
      "\n",
      "if len(X.shape) < 2:\n",
      "    X.shape += (1,)\n",
      "\n",
      "for train, test in cv.KFold(X.shape[0], n_folds=10, shuffle=True):\n",
      "    X_train = X[train]\n",
      "    X_test = X[test]\n",
      "    y_train = y[train]\n",
      "    y_test = y[test]\n",
      "\n",
      "    clf.fit(X_train, y_train)\n",
      "    y_pred = clf.predict(X_test)\n",
      "\n",
      "    # TODO: add combinatorial feature discrimination\n",
      "\n",
      "    acc = accuracy_score(y_test, y_pred)\n",
      "    auc = roc_auc_score(y_test, y_pred)\n",
      "    cm = np.add(cm, confusion_matrix(y_test, y_pred))\n",
      "    accs.append(acc)\n",
      "    aucs.append(auc)\n",
      "\n",
      "# averaging classification metrics over\n",
      "print 'Avg accuracy: {0:.2f} +/- {1:.2f}'.format(np.mean(accs), np.std(accs))\n",
      "print 'Avg AUC ROC: {0:.2f} +/- {1:.2f}'.format(np.mean(aucs), np.std(aucs))\n",
      "print 'Avg confusion matrix:'\n",
      "print(np.divide(cm, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg accuracy: 1.00 +/- 0.00\n",
        "Avg AUC ROC: 1.00 +/- 0.00\n",
        "Avg confusion matrix:\n",
        "[[ 10.   0.]\n",
        " [  0.  10.]]\n"
       ]
      }
     ],
     "prompt_number": 328
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    }
   ],
   "metadata": {}
  }
 ]
}