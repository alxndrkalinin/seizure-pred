{
 "metadata": {
  "name": "",
  "signature": "sha256:2d10d8696b1dff99ad5a8c64327e7541724a0d25068e3fb0a2d3a66c4a9636f4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from __future__ import division\n",
      "import os, sys, glob, operator, itertools\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats, fft\n",
      "from scipy.signal import butter, lfilter\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn import cross_validation as cv\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.feature_selection import RFECV\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RandomForestClassifierWithCoef(RandomForestClassifier):\n",
      "    def fit(self, *args, **kwargs):\n",
      "        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)\n",
      "        self.coef_ = self.feature_importances_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyDir = 'healthy'\n",
      "epilepticDir = 'epileptic'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readData(dirName):\n",
      "    pwd = os.path.dirname(os.path.realpath(dirName))\n",
      "\n",
      "    allFiles = glob.glob(pwd + '/' + dirName + '/*.txt')\n",
      "    frames = []\n",
      "\n",
      "    for fileName in allFiles:\n",
      "        series = pd.read_csv(fileName, header=None, sep='\\n', index_col=False)\n",
      "        series = series.transpose()\n",
      "        frames.append(series)\n",
      "    \n",
      "    df = pd.concat(frames)\n",
      "    df = df.reset_index(drop = 1)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyDf = readData(healthyDir)\n",
      "epilepticDf = readData(epilepticDir)\n",
      "print(healthyDf.shape)\n",
      "print(epilepticDf.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 4097)\n",
        "(100, 4097)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
      "    nyq = 0.5 * fs\n",
      "    low = lowcut / nyq\n",
      "    high = highcut / nyq\n",
      "    b, a = butter(order, [low, high], btype = 'band')\n",
      "    return b, a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare 8 overlapping log-spaced bandpass filters between 0.53 and 40Hz\n",
      "filters = []\n",
      "fs = 173.61\n",
      "for i in range(8):\n",
      "    x = np.logspace(np.log10(0.53), np.log10(40), 10)\n",
      "    filters.append(butter_bandpass(x[i], np.floor(x[i + 2]), fs, 3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create combinatorial filter sets up to size 4. Output is global idexing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List of all possible combinations of 4 or fewer filters\n",
      "wis = list(itertools.chain(itertools.combinations(range(8), 1),\n",
      "                           itertools.combinations(range(8), 2),\n",
      "                           itertools.combinations(range(8), 3),\n",
      "                           itertools.combinations(range(8), 4)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_features(signal):\n",
      "    feat = []\n",
      "    for b, a in filters:\n",
      "        f = lfilter(b, a, signal)\n",
      "        covar = np.cov(f)\n",
      "        ampl = np.sum(np.absolute(f)) / np.sum(np.absolute(signal).sum())\n",
      "        power = np.sum(np.power(f, 2)) / np.sum(np.power(signal, 2).sum())\n",
      "        feat = np.append(feat, [covar, ampl, power])\n",
      "    return pd.Series(feat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "healthyLabels = np.zeros(healthyDf.shape[0], dtype=np.int)\n",
      "epilepticLables = np.ones(epilepticDf.shape[0], dtype=np.int)\n",
      "\n",
      "labels = np.append(healthyLabels, epilepticLables)\n",
      "\n",
      "healthyFeat = healthyDf.apply(extract_features, axis=1)\n",
      "epilepticFeat = epilepticDf.apply(extract_features, axis=1)\n",
      "\n",
      "features = healthyFeat.append(epilepticFeat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getFeaturesForFilterSet (features, filterSet):\n",
      "    return pd.concat([features.iloc[:, 3 * filter : 3 * (filter + 1)] for filter in filterSet], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auc_scores = []\n",
      "ig_scores = []\n",
      "rfs_scores = []\n",
      "\n",
      "def binFreq(arr):\n",
      "    nonZeroFreq = np.count_nonzero(arr) / len(arr)\n",
      "    return [nonZeroFreq, 1 - nonZeroFreq]\n",
      "\n",
      "for w in wis:\n",
      "    \n",
      "    # get features for current set of filters using global indices\n",
      "    featureSet = getFeaturesForFilterSet(features, w)\n",
      "    \n",
      "    y = labels\n",
      "    X = featureSet.values\n",
      "\n",
      "    ps = []\n",
      "    fs = []\n",
      "    rfs = []\n",
      "    for train, test in cv.ShuffleSplit(X.shape[0], random_state=42):\n",
      "        X_train = X[train]\n",
      "        X_test = X[test]\n",
      "        y_train = y[train]\n",
      "        y_test = y[test]\n",
      "\n",
      "        clf = SGDClassifier(loss='log', penalty='l1', alpha=0.0001)    \n",
      "        clf.fit(X_train, y_train)     \n",
      "        y_pred = clf.predict(X_test)\n",
      "\n",
      "        ras = roc_auc_score(y_test, y_pred)\n",
      "        igs = stats.entropy(binFreq(y_pred), binFreq(y_test))\n",
      "        ps.append(ras)\n",
      "        fs.append(igs)\n",
      "\n",
      "        \n",
      "    ps = np.array(ps)\n",
      "    fs = np.array(fs)\n",
      "    rfs = np.array(rfs)\n",
      "    auc_scores.append(ps.mean())\n",
      "    ig_scores.append(fs.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select 5 best filter sets from each selection scheme\n",
      "best_auc = sorted(zip(auc_scores, wis))[-5:]\n",
      "best_ig = sorted(zip(ig_scores, wis))[:5]\n",
      "\n",
      "bestAucInd = tuple(x[1] for x in best_auc)\n",
      "bestIgInd = tuple(x[1] for x in best_ig)\n",
      "\n",
      "iterBestAucInd = itertools.chain.from_iterable(bestAucInd)\n",
      "\n",
      "# choose filter sets that include filters from best AUC list\n",
      "elems = set(iterBestAucInd)\n",
      "bestFilters = [tup for tup in bestIgInd if elems.issuperset(tup)]\n",
      "print(bestFilters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0.58969336219336221, (0, 1, 2, 3)), (0.59023809523809523, (0, 1, 6)), (0.610669191919192, (0, 3)), (0.61897907647907657, (0, 2, 3)), (0.62044372294372307, (0, 1, 3))]\n",
        "[(0.33872509586235128, (0, 2, 3, 5)), (0.352665514604522, (0, 3)), (0.35804412756429993, (0, 1, 3)), (0.37052472784659302, (0, 2, 3)), (0.39300911656660331, (0, 2, 3, 4))]\n",
        "[(0, 3), (0, 1, 3), (0, 2, 3)]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifiers = [\n",
      "    LinearSVC(dual=False),\n",
      "    SVC(),\n",
      "    Lasso(),\n",
      "    KNeighborsClassifier(),\n",
      "    AdaBoostClassifier(),\n",
      "    RandomForestClassifier(n_estimators=200, n_jobs=-1),\n",
      "    GradientBoostingClassifier(n_estimators=200, warm_start=False)\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filterBestAuc = []\n",
      "\n",
      "for featSet in bestFilters:\n",
      "    print('\\nFILTERS:' + str(featSet))\n",
      "    \n",
      "    featureSet = getFeaturesForFilterSet(features, featSet)\n",
      "    \n",
      "    y = labels\n",
      "    X = featureSet.values\n",
      "    \n",
      "    clfs_auc = []\n",
      "\n",
      "    for clf in classifiers:\n",
      "\n",
      "        aucs = []\n",
      "    \n",
      "        for train, test in cv.KFold(X.shape[0], n_folds=5, shuffle=True, random_state=24):\n",
      "            X_train = X[train]\n",
      "            X_test = X[test]\n",
      "            y_train = y[train]\n",
      "            y_test = y[test]\n",
      "            \n",
      "            clf.fit(X_train, y_train)\n",
      "            y_pred = clf.predict(X_test)\n",
      "\n",
      "            auc = roc_auc_score(y_test, y_pred)\n",
      "            aucs.append(auc)\n",
      "\n",
      "        avg_auc = np.mean(aucs)\n",
      "        print(avg_auc)\n",
      "        clfs_auc.append(avg_auc)\n",
      "\n",
      "    best_auc_clf = sorted(zip(clfs_auc, classifiers))[-1:]\n",
      "    print(best_auc_clf)\n",
      "    filterBestAuc.append(best_auc_clf[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "FILTERS:(0, 3)\n",
        "0.618580542265\n",
        "0.518520733652\n",
        "0.991777146465\n",
        "0.994444444444\n",
        "1.0\n",
        "0.994444444444"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False))]\n",
        "\n",
        "FILTERS:(0, 1, 3)\n",
        "0.800423351159\n",
        "0.5\n",
        "0.992818813131\n",
        "0.994444444444\n",
        "1.0\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(1.0, RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "            oob_score=False, random_state=None, verbose=0))]\n",
        "\n",
        "FILTERS:(0, 2, 3)\n",
        "0.662574272133\n",
        "0.5\n",
        "0.991792929293\n",
        "0.988194444444\n",
        "1.0\n",
        "0.994444444444"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False))]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FilterSets = sorted(zip(filterBestAuc, bestFilters))\n",
      "scores = [set[0][0] for set in FilterSets]\n",
      "numMaxScores = len([i for i, s in enumerate(scores) if s == scores[-1:]])\n",
      "bestFilterSets = FilterSets[-1 * numMaxScores:]\n",
      "print(bestFilterSets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[((1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)), (0, 2, 3)), ((1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)), (0, 3)), ((1.0, RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "            oob_score=False, random_state=None, verbose=0)), (0, 1, 3))]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def eliminateFeatures(fs, clf):\n",
      "        featureSet = getFeaturesForFilterSet(features, fs[1])\n",
      "        X = featureSet.values\n",
      "\n",
      "        rfecv = RFECV(estimator=clf, step=1, cv=cv.KFold(X.shape[0], n_folds=5, shuffle=True), scoring='roc_auc')\n",
      "        rfecv.fit(X, y)\n",
      "\n",
      "        print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
      "\n",
      "        # Plot number of features VS. cross-validation scores\n",
      "        plt.figure()\n",
      "        plt.xlabel(\"Number of features selected\")\n",
      "        plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
      "        plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
      "        plt.show()\n",
      "        \n",
      "        return rfecv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalFilterClfSets = []\n",
      "\n",
      "for i, fs in enumerate(bestFilterSets):\n",
      "    \n",
      "    print(fs)\n",
      "    print(i)\n",
      "\n",
      "    clf = fs[0][1]\n",
      "    \n",
      "    if not hasattr(clf, 'coef_'):\n",
      "        if ((clf.__class__.__name__ == 'RandomForestClassifier')):\n",
      "            clf = RandomForestClassifierWithCoef(n_estimators=200, n_jobs=-1)\n",
      "            rfecv = eliminateFeatures(fs, clf)\n",
      "            finalFilterClfSets.append((fs, clf, rfecv))\n",
      "        else:\n",
      "            print('Cannot do further feature reduction for ' + str(clf))\n",
      "            print('Used filters: ' + str(fs[1]))\n",
      "            print('Achieved accuracy: ' + str(fs[0][0]))\n",
      "    else:\n",
      "        print('OK GO!')\n",
      "        rfecv = eliminateFeatures(fs, clf)\n",
      "        finalFilterClfSets.append((fs, clf, rfecv))\n",
      "        \n",
      "print(finalFilterClfSets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "((1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)), (0, 2, 3))\n",
        "0\n",
        "Cannot do further feature reduction for GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)\n",
        "Used filters: (0, 2, 3)\n",
        "Achieved accuracy: 1.0\n",
        "((1.0, GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)), (0, 3))\n",
        "1\n",
        "Cannot do further feature reduction for GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=200,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)\n",
        "Used filters: (0, 3)\n",
        "Achieved accuracy: 1.0\n",
        "((1.0, RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "            oob_score=False, random_state=None, verbose=0)), (0, 1, 3))\n",
        "2\n",
        "Optimal number of features : 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEbCAYAAADNr2OMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10cf3d110>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(((1.0, RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "            oob_score=False, random_state=None, verbose=0)), (0, 1, 3)), RandomForestClassifierWithCoef(bootstrap=True, compute_importances=None,\n",
        "                criterion='gini', max_depth=None, max_features='auto',\n",
        "                max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "                min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "                oob_score=False, random_state=None, verbose=0), RFECV(cv=sklearn.cross_validation.KFold(n=200, n_folds=5, shuffle=True, random_state=None),\n",
        "   estimator=RandomForestClassifierWithCoef(bootstrap=True, compute_importances=None,\n",
        "                criterion='gini', max_depth=None, max_features='auto',\n",
        "                max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "                min_samples_split=2, n_estimators=200, n_jobs=-1,\n",
        "                oob_score=False, random_state=None, verbose=0),\n",
        "   estimator_params={}, loss_func=None, scoring='roc_auc', step=1,\n",
        "   verbose=0))]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find best classifier with minimal number of filters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minFiltSetInd, minFiltSetLen = min(enumerate([len(fsClfSet[0][1])for fsClfSet in finalFilterClfSets]), key=operator.itemgetter(1))\n",
      "print(finalFilterClfSets[minFiltSetInd][0][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0, 1, 3)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accs = []\n",
      "aucs = []\n",
      "cm = np.zeros((2,2))\n",
      "\n",
      "selectedFeatInd = finalFilterClfSets[minFiltSetInd][2].get_support(indices=True)\n",
      "featureSet = getFeaturesForFilterSet(features, finalFilterClfSets[minFiltSetInd][0][1])\n",
      "X = featureSet.iloc[:, selectedFeatInd].values\n",
      "\n",
      "# workaround for KFold that requires (n, 1) shape for 1d arrays\n",
      "if len(X.shape) < 2:\n",
      "    X.shape += (1,)\n",
      "\n",
      "for train, test in cv.KFold(X.shape[0], n_folds=10, shuffle=True):\n",
      "    X_train = X[train]\n",
      "    X_test = X[test]\n",
      "    y_train = y[train]\n",
      "    y_test = y[test]\n",
      "\n",
      "    clf.fit(X_train, y_train)\n",
      "    y_pred = clf.predict(X_test)\n",
      "\n",
      "    # TODO: add combinatorial feature discrimination\n",
      "\n",
      "    acc = accuracy_score(y_test, y_pred)\n",
      "    auc = roc_auc_score(y_test, y_pred)\n",
      "    cm = np.add(cm, confusion_matrix(y_test, y_pred))\n",
      "    accs.append(acc)\n",
      "    aucs.append(auc)\n",
      "\n",
      "# averaging classification metrics over\n",
      "print 'Avg accuracy: {0:.2f} +/- {1:.2f}'.format(np.mean(accs), np.std(accs))\n",
      "print 'Avg AUC ROC: {0:.2f} +/- {1:.2f}'.format(np.mean(aucs), np.std(aucs))\n",
      "print 'Avg confusion matrix:'\n",
      "print(np.divide(cm, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg accuracy: 1.00 +/- 0.00\n",
        "Avg AUC ROC: 1.00 +/- 0.00\n",
        "Avg confusion matrix:\n",
        "[[ 10.   0.]\n",
        " [  0.  10.]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}